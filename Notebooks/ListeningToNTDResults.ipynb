{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hello!\n",
    "\n",
    "This Notebook is associated with the ICASSP2022 submission, presenting audio outputs of the Nonnegative Tucker Decomposition (NTD) when optimizing different loss functions. In particular, the three evaluated loss functions are three special cases of the more general $\\beta$-divergence:\n",
    " - The Euclidean norm, $\\beta = 2$,\n",
    " - The Kullback-Leibler (KL) divergence, $\\beta = 1$,\n",
    " - The Itakura-Saito (IS) divergence, $\\beta = 0$.\n",
    "\n",
    "More details about our algorithm are to be found in the ICASSP submsission (which should be the reason of your presence on this page). Audio signals are obtained by applying the Griffin-Lim algorithm to STFT.\n",
    "\n",
    "This notebook will present signals, showing results of:\n",
    " - The Griffin-Lim algortihm itself, by recomposing the phase of the original STFT of the song, to serve as a baseline for the other estimations. This baseline condition already presents some artifacts on the reconstructed signal.\n",
    " - A comparison of the decomposition results with the three different loss functions. This comparison is obtained by omparing:\n",
    "   - The reconstructed song itself, result of the whole decomposition,\n",
    "   - The different patterns ($W G_{[:,:,i]} H^T$, with $i$ the pattern index), obtained by the decomposition.\n",
    "   \n",
    "Note though that signals representing songs will be limited to the first 16 bars, in order to limit the size of this HTML page.\n",
    "\n",
    "We insist on the fact that, while audio signals are listenable, **they are not of profesional musical quality** either due to inaccuracies in the decomposition or due to the phase-estimation algorithm that we use (Griffin-Lim). Improving the reconstruction of these signals could constitute future work.\n",
    "\n",
    "In the meantime, we believe that these audio examples are good examples of the potential and outputs of the NTD, and allow to qualitatively evaluate the differences between the different loss functions.\n",
    "\n",
    "# Imports\n",
    "Let's start with importing external librairies (which are installed automatically if you used `pip install`, otherwise you should install them manually)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-05T15:17:41.224624Z",
     "start_time": "2021-10-05T15:17:38.902285Z"
    }
   },
   "outputs": [],
   "source": [
    "# External imports\n",
    "# Module for manipulating arrays\n",
    "import numpy as np\n",
    "\n",
    "# Module for loading signals\n",
    "import soundfile as sf\n",
    "\n",
    "# Module for manipulating signals, notably \n",
    "import librosa\n",
    "\n",
    "import IPython.display as ipd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now, let's import the `nn_fac` and `MusicNTD` code (respectively code for Nonnegative Factorizations methods and for everything else (data manipulation, segmentation, etc) associated with NTD for music segmenation):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-05T15:17:41.549943Z",
     "start_time": "2021-10-05T15:17:41.225621Z"
    }
   },
   "outputs": [],
   "source": [
    "# Module containing our NTD resolution algorithm\n",
    "import nn_fac.ntd as NTD\n",
    "\n",
    "# Module encapsulating the computation of features from the signal\n",
    "import musicntd.model.features as features\n",
    "\n",
    "# General module for manipulating data: conversion between time, bars, frame indexes, loading of data, ...\n",
    "import musicntd.data_manipulation as dm\n",
    "\n",
    "# Module constructing the tensor, starting from the spectrogram\n",
    "import musicntd.tensor_factory as tf\n",
    "\n",
    "# Plotting module\n",
    "from musicntd.model.current_plot import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we need to load the song to decompose. We used Come Together from The Beatles as example, but feel free to chose any song you'd like! (in wav though.)\n",
    "\n",
    "NB: this comment only applies of you're compiling the Notebook, and not reading the HTML, as the HTML is static."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-05T15:18:45.173624Z",
     "start_time": "2021-10-05T15:17:41.551967Z"
    }
   },
   "outputs": [],
   "source": [
    "# Song\n",
    "song_path = \"C:/Users/amarmore/this_folder/The Beatles - Come Together.wav\"\n",
    "the_signal, sampling_rate = sf.read(song_path)\n",
    "\n",
    "# Get the downbeats\n",
    "bars = dm.get_bars_from_audio(song_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STFT\n",
    "Let's compute the STFT of the song:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-05T15:20:51.306682Z",
     "start_time": "2021-10-05T15:18:45.175976Z"
    }
   },
   "outputs": [],
   "source": [
    "n_fft=2048\n",
    "hop_length = 32\n",
    "\n",
    "stft_complex = librosa.core.stft(np.asfortranarray(the_signal[:,0]), n_fft=n_fft, hop_length = hop_length)\n",
    "for i in range(1,the_signal.shape[1]):\n",
    "    stft_complex += librosa.core.stft(np.asfortranarray(the_signal[:,i]), n_fft=n_fft, hop_length = hop_length)\n",
    "mag, phase = librosa.magphase(stft_complex, power=1) # Magnitude spectrogram"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and then form the tensor-spectrogram of this STFT:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-05T15:20:55.836015Z",
     "start_time": "2021-10-05T15:20:51.333698Z"
    }
   },
   "outputs": [],
   "source": [
    "hop_length_seconds = hop_length / sampling_rate\n",
    "subdivision = 96\n",
    "\n",
    "tensor_stft = tf.tensorize_barwise(mag, bars, hop_length_seconds, subdivision)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We reconstruct the song from the unfolded tensor spectrogram. Hence, the song will be reconstructed from the 96 chosen samples per bar.\n",
    "\n",
    "To reconstruct the song, the algorithm needs the hop length of the STFT. As bars can be of different length, we compute the median hop length from the different bars, and applies it to all bars in our song."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-05T15:20:55.866804Z",
     "start_time": "2021-10-05T15:20:55.841990Z"
    }
   },
   "outputs": [],
   "source": [
    "hops = []\n",
    "for bar_idx in range(tensor_stft.shape[2]):\n",
    "    len_sig = bars[bar_idx+1][1] - bars[bar_idx+1][0]\n",
    "    hop = int(len_sig/96 * sampling_rate)\n",
    "    hops.append(hop)\n",
    "median_hop = int(np.median(hops))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's recreate the signal from the barwise STFT, in order to study the reconstruction quality of the Griffin-Lim algorithm. We limit the song to a certain number of bars (not to overload the final HTML file)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-05T15:21:05.405303Z",
     "start_time": "2021-10-05T15:20:55.870787Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "nb_bars = 16 # you can set it to 89 if you use the executable format, and listen to the whole song.\n",
    "time = nb_bars * subdivision\n",
    "audio_stft = librosa.griffinlim(np.reshape(tensor_stft[:,:,:nb_bars], (1025, time), order = 'F'), hop_length = median_hop)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's hear it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-05T15:21:05.629037Z",
     "start_time": "2021-10-05T15:21:05.410770Z"
    }
   },
   "outputs": [],
   "source": [
    "ipd.Audio(audio_stft, rate=sampling_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We already see some artifacts coming from the reconstruction. Hence, reconstructed signals won't be better than this one, which is already disturbed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NTD: Nonnegative Tucker Decomposition\n",
    "Let's compute the NTD of this tensor-spectrogram, and study the reconstructed signal and the barwise patterns obtained in the decomposition.\n",
    "\n",
    "As a recall, NTD is a tensor decomposition method, which can be used to retrieve patterns from data.\n",
    "\n",
    "<img src=\"imgs/NTD.png\" width=\"500\"/>\n",
    "\n",
    "We refer to the ICASSP submission or to [1] for details.\n",
    "\n",
    "First, we need to set the dimensions of the decomposition, corresponding to the core dimensions. They have set empirically here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-05T15:21:05.680087Z",
     "start_time": "2021-10-05T15:21:05.632066Z"
    }
   },
   "outputs": [],
   "source": [
    "ranks = [32,24,12] #Dimensions of the decomposition\n",
    "n_iter_max = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## $\\beta$ = 2: Euclidean nom\n",
    "Below is executed the NTD with the HALS algorithm, optimizing the euclidean norm ($\\beta$-divergence with $\\beta = 2$) between the original and the reconstructed tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-05T15:22:31.462929Z",
     "start_time": "2021-10-05T15:21:05.684119Z"
    }
   },
   "outputs": [],
   "source": [
    "core_beta2, factors_beta2 = NTD.ntd(tensor_stft, ranks = ranks, init = \"tucker\", verbose = False, deterministic = True,\n",
    "                    sparsity_coefficients = [None, None, None, None], normalize = [True, True, False, True], mode_core_norm = 2, n_iter_max = n_iter_max)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## $\\beta$ = 1: Kullback-Leibler divergence\n",
    "Below is executed the NTD with the MU algorithm optimizing the Kullback-Leibler divergence ($\\beta$-divergence with $\\beta = 1$) between the original and the reconstructed tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-05T15:25:25.963737Z",
     "start_time": "2021-10-05T15:22:31.465396Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "core_beta1, factors_beta1 = NTD.ntd_mu(tensor_stft, ranks = ranks, init = \"tucker\", verbose = False, deterministic = True, beta = 1,\n",
    "                    sparsity_coefficients = [None, None, None, None], normalize = [True, True, False, True], mode_core_norm = 2, n_iter_max = n_iter_max)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## $\\beta = 0$: Itakura-Saito divergence\n",
    "Below is executed the NTD with the MU algorithm optimizing the Itakura-Saito divergence ($\\beta$-divergence with $\\beta = 0$) between the original and the reconstructed tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-05T15:28:17.796213Z",
     "start_time": "2021-10-05T15:25:25.965400Z"
    }
   },
   "outputs": [],
   "source": [
    "core_beta0, factors_beta0 = NTD.ntd_mu(tensor_stft, ranks = ranks, init = \"tucker\", verbose = False, deterministic = True, beta = 0,\n",
    "                    sparsity_coefficients = [None, None, None, None], normalize = [True, True, False, True], mode_core_norm = 2, n_iter_max = n_iter_max)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Listening to the reconstructed songs\n",
    "Having decomposed the song with the 3 different losses, we will now compare the resulting decompositions by listening to the resulting factorization.\n",
    "\n",
    "Hence, we unfold the NTD results and use the Griffin-Lim algorithm to reconstruct a signal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-05T15:28:17.817152Z",
     "start_time": "2021-10-05T15:28:17.796842Z"
    }
   },
   "outputs": [],
   "source": [
    "# function reconstructing the signal from the ntd results.\n",
    "def reconstruct_song_from_ntd(core, factors, bars, nb_bars = None):\n",
    "    if nb_bars == None:\n",
    "        nb_bars = factors[2].shape[0]\n",
    "    barwise_spec_shape = (factors[0]@core[:,:,0]@factors[1].T).shape\n",
    "    signal_content = None\n",
    "    for bar_idx in range(nb_bars):\n",
    "        len_sig = bars[bar_idx+1][1] - bars[bar_idx+1][0]\n",
    "        hop = int(len_sig/96 * sampling_rate)\n",
    "        patterns_weights = factors[2][bar_idx]\n",
    "        bar_content = np.zeros(barwise_spec_shape)\n",
    "        for pat_idx in range(ranks[2]):\n",
    "            bar_content += patterns_weights[pat_idx] * factors[0]@core[:,:,pat_idx]@factors[1].T\n",
    "        signal_content = np.concatenate((signal_content, bar_content), axis=1) if signal_content is not None else bar_content\n",
    "    reconstructed_song = librosa.griffinlim(signal_content, hop_length = hop)\n",
    "    return reconstructed_song"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-05T15:28:44.121446Z",
     "start_time": "2021-10-05T15:28:17.819322Z"
    }
   },
   "outputs": [],
   "source": [
    "audio_beta2 = reconstruct_song_from_ntd(core_beta2, factors_beta2, bars, nb_bars = nb_bars)\n",
    "signal_beta2 = ipd.Audio(audio_beta2, rate=sampling_rate)\n",
    "\n",
    "audio_beta1 = reconstruct_song_from_ntd(core_beta1, factors_beta1, bars, nb_bars = nb_bars)\n",
    "signal_beta1 = ipd.Audio(audio_beta1, rate=sampling_rate)\n",
    "\n",
    "audio_beta0 = reconstruct_song_from_ntd(core_beta0, factors_beta0, bars, nb_bars = nb_bars)\n",
    "signal_beta0 = ipd.Audio(audio_beta0, rate=sampling_rate)\n",
    "\n",
    "plot_audio_diff_beta_in_dataframe(signal_beta2, signal_beta1, signal_beta0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We hear a particularly strong difference (in our test example) between $\\beta = 2$ and both $\\beta = 1, 0$.\n",
    "\n",
    "Both $\\beta = 1, 0$ seem to capture melodic lines in the song, while $\\beta = 2$ seems to focus on rhythmic and low-frequential aspects."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Listening to all patterns\n",
    "The interesting aspect of NTD is its supposed ability to capture patterns in the song, as discussed in [1].\n",
    "\n",
    "Hence, by computing the appropriate products ($W G_{[:,:,i]} H^T$, with $i$ the pattern index), we can recompose the spectrograms forming each pattern, and use the Griffin-Lim algorithm to reconstruct these STFT into signals. This is what is made in the following cells, where every listenable file correspond to a pattern obtained in the decomposition (12 for each $\\beta$ value in our example)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-05T15:28:44.139026Z",
     "start_time": "2021-10-05T15:28:44.124438Z"
    }
   },
   "outputs": [],
   "source": [
    "def compute_pattern_signals(core, factors, hop_length):\n",
    "    audios_list = []\n",
    "    for i in range(factors[2].shape[1]):\n",
    "        pattern = factors[0]@core[:,:,i]@factors[1].T\n",
    "        audio = librosa.griffinlim(pattern, hop_length = hop_length)\n",
    "        signal_audio = ipd.Audio(audio, rate=sampling_rate)\n",
    "        audios_list.append(signal_audio)\n",
    "    return audios_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-05T15:29:02.035176Z",
     "start_time": "2021-10-05T15:28:44.142786Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "patterns_beta2 = compute_pattern_signals(core_beta2, factors_beta2, hop_length = median_hop)\n",
    "patterns_beta1 = compute_pattern_signals(core_beta1, factors_beta1, hop_length = median_hop)\n",
    "patterns_beta0 = compute_pattern_signals(core_beta0, factors_beta0, hop_length = median_hop)\n",
    "\n",
    "plot_audio_diff_beta_in_dataframe(patterns_beta2, patterns_beta1, patterns_beta0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, we concluded empirically that both $\\beta = 1, 0$ were able to capture more interpretable patterns in terms of human perception than $\\beta = 2$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# References\n",
    "\n",
    "[1] Marmoret, A., Cohen, J., Bertin, N., & Bimbot, F. (2020, October). Uncovering Audio Patterns in Music with Nonnegative Tucker Decomposition for Structural Segmentation. In ISMIR 2020-21st International Society for Music Information Retrieval."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
